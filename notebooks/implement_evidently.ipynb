{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae87315-e4bb-4d91-9c93-0cfa304bae26",
   "metadata": {},
   "source": [
    "## List of features from Evidently we will use\n",
    "Data drift doc: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html  \n",
    "Data drift ref paper: https://arxiv.org/pdf/1810.11953.pdf\n",
    "- Data Quality\n",
    "    - Metrics\n",
    "        - ConflictPredictionMetric (for cur)\n",
    "        - ConflictTargetMetric (for ref)\n",
    "    - Tests\n",
    "        - TestConflictPrediction (for cur)\n",
    "        - TestConflictTarget (for ref)\n",
    "- Data Drift\n",
    "    - Metrics \n",
    "        - EmbeddingsDriftMetric (MMD for UAE)\n",
    "        - EmbeddingsDriftMetric (Ratio (KS) for UAE)\n",
    "        - EmbeddingsDriftMetric (Euclidean distance for UAE)\n",
    "        - EmbeddingsDriftMetric (Model (0.7 thr) for UAE)\n",
    "        - EmbeddingsDriftMetric (MMD for BBSD)\n",
    "        - EmbeddingsDriftMetric (Ratio (KS) for BBSD)\n",
    "    - Tests\n",
    "        - TestEmbeddingsDrift (MMD for UAE)\n",
    "        - TestEmbeddingsDrift (Ratio (KS) for UAE)\n",
    "        - TestEmbeddingsDrift (Euclidean distance for UAE)\n",
    "        - TestEmbeddingsDrift (Model (0.7 thr) for UAE)\n",
    "        - TestEmbeddingsDrift (MMD for BBSD)\n",
    "        - TestEmbeddingsDrift (Ratio (KS) for BBSD)\n",
    "     \n",
    "**Note**: MMD is a popular kernel-based technique for multivariate two-sample testing and KS is a popluar alternative of MMG for multiple univariate tests. In the paper, the author use Bonferroni correction for aggregating multiple univariate results for KS. In Evidently's doc, they also support the KS test, but they use the word **\"share of drifted embeddings\"** for a single final drift score which, honestly, we don't know what it means (maybe average or percentage?). Anyways, we did use Evidently's KS implementation here for the sake of simplicity. If you are more interested in KS using Bonferroni correction as in the paper, be sure to check Alibi Detect documentation, they have implemented according to the ref paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c59bbe-dd4d-46b9-8241-12a2072557a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.test_preset import NoTargetPerformanceTestPreset, DataDriftTestPreset\n",
    "from evidently.ui.remote import RemoteWorkspace\n",
    "from evidently.ui.workspace import Workspace, WorkspaceBase\n",
    "from evidently.metrics import (ConflictPredictionMetric, DatasetCorrelationsMetric,\n",
    "                               EmbeddingsDriftMetric, ConflictTargetMetric)\n",
    "from evidently.tests import (TestConflictPrediction, TestPredictionFeaturesCorrelations,\n",
    "                             TestEmbeddingsDrift, TestConflictTarget)\n",
    "from evidently.ui.dashboards import (CounterAgg, DashboardPanelCounter, DashboardPanelPlot, \n",
    "                                     PanelValue, PlotType, ReportFilter)\n",
    "from evidently.metrics.data_drift.embedding_drift_methods import model, ratio, distance, mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19827c8-45aa-4fd7-884b-33fd419179e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report():\n",
    "    data_drift_report = Report(\n",
    "        metrics=[\n",
    "            ConflictTargetMetric(),\n",
    "            ConflictPredictionMetric(),\n",
    "            # mmd with uae # note: currently, mmd failed. please check docs\n",
    "            EmbeddingsDriftMetric('uae', drift_method = mmd(threshold = 0.015, quantile_probability = 0.95)),\n",
    "            # ks with uae\n",
    "            EmbeddingsDriftMetric('uae', drift_method = ratio(\n",
    "                                        component_stattest='ks',\n",
    "                                        threshold = 0.05\n",
    "                                    )\n",
    "                                 ),\n",
    "            # euclidean with uae\n",
    "            EmbeddingsDriftMetric('uae', \n",
    "                                  drift_method = distance(\n",
    "                                      dist = 'euclidean',\n",
    "                                      threshold = 0.2\n",
    "                                  )\n",
    "                                 ),\n",
    "            # model with uae\n",
    "            EmbeddingsDriftMetric('uae', drift_method = model(threshold = 0.75)),\n",
    "            # mmd with bbsd\n",
    "            EmbeddingsDriftMetric('bbsd', drift_method = mmd(threshold = 0.015, quantile_probability = 0.95)),\n",
    "            # ks with bbsd\n",
    "            EmbeddingsDriftMetric('bbsd', drift_method = ratio(\n",
    "                                        component_stattest='ks',\n",
    "                                        threshold = 0.05\n",
    "                                    )\n",
    "                                 ),\n",
    "        ]\n",
    "    )\n",
    "    return data_drift_report\n",
    "\n",
    "\n",
    "def create_test_suite():\n",
    "    data_drift_test_suite = TestSuite(\n",
    "        tests=[\n",
    "            TestConflictTarget(),\n",
    "            TestConflictPrediction(),\n",
    "            # mmd with uae\n",
    "            TestEmbeddingsDrift('uae', drift_method = mmd(threshold = 0.015, quantile_probability = 0.95)),\n",
    "            # ks with uae\n",
    "            TestEmbeddingsDrift('uae', drift_method = ratio(\n",
    "                                        component_stattest='ks',\n",
    "                                        threshold = 0.05\n",
    "                                    )\n",
    "                                 ),\n",
    "            # euclidean with uae\n",
    "            TestEmbeddingsDrift('uae', \n",
    "                                  drift_method = distance(\n",
    "                                      dist = 'euclidean',\n",
    "                                      threshold = 0.2\n",
    "                                  )\n",
    "                                 ),\n",
    "            # model with uae\n",
    "            TestEmbeddingsDrift('uae', drift_method = model(threshold = 0.75)),\n",
    "            # mmd with bbsd\n",
    "            TestEmbeddingsDrift('bbsd', drift_method = mmd(threshold = 0.015, quantile_probability = 0.95)),\n",
    "            # ks with bbsd\n",
    "            TestEmbeddingsDrift('bbsd', drift_method = ratio(\n",
    "                                        component_stattest='ks',\n",
    "                                        threshold = 0.05\n",
    "                                    )\n",
    "                                 ),\n",
    "        ]\n",
    "    )\n",
    "    return data_drift_test_suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cee838f-f2fa-43e5-b641-716a9ab52f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dashboard(project, project_desc: str):\n",
    "    project.description = project_desc\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelCounter(\n",
    "            filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "            agg=CounterAgg.NONE,\n",
    "            title=\"Production Model Monitor!\",\n",
    "        )\n",
    "    )\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelCounter(\n",
    "            filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "            agg=CounterAgg.NONE,\n",
    "            title=\"Production Data Quality\",\n",
    "        )\n",
    "    )\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelCounter(\n",
    "            title=\"Number of conflicts in Prediction\",\n",
    "            filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "            value=PanelValue(\n",
    "                metric_id=\"ConflictPredictionMetric\",\n",
    "                field_path=ConflictPredictionMetric.fields.current.number_not_stable_prediction,\n",
    "            ),\n",
    "            text=\"count\",\n",
    "            agg=CounterAgg.LAST,\n",
    "            size=1,\n",
    "        )\n",
    "    )\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelCounter(\n",
    "            title=\"Number of conflicts in Target (GT)\",\n",
    "            filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "            value=PanelValue(\n",
    "                metric_id=\"ConflictTargetMetric\",\n",
    "                field_path=ConflictTargetMetric.fields.number_not_stable_target,\n",
    "            ),\n",
    "            text=\"count\",\n",
    "            agg=CounterAgg.LAST,\n",
    "            size=1,\n",
    "        )\n",
    "    )\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelCounter(\n",
    "            filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "            agg=CounterAgg.NONE,\n",
    "            title=\"Drift Detection\",\n",
    "        )\n",
    "    )\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelCounter(\n",
    "            title=\"Drift Score\",\n",
    "            filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "            value=PanelValue(\n",
    "                metric_id=\"EmbeddingsDriftMetric\",\n",
    "                field_path=EmbeddingsDriftMetric.fields.drift_score,\n",
    "                legend=\"score\",\n",
    "            ),\n",
    "            text=\"latest\",\n",
    "            agg=CounterAgg.LAST,\n",
    "            size=2,\n",
    "        )\n",
    "    )\n",
    "    project.save()\n",
    "    return project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3500e77a-dd35-4ee6-9ae6-d78db8794e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, List, Dict\n",
    "from collections import defaultdict\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from db_tables import APILogTable, PredictionsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5abc84a6-eef7-4c04-b139-31535742442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_db_session(engine: sqlalchemy.engine) -> sqlalchemy.orm.Session:\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e5c63a-edb4-4cbe-ad29-983460af741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cur_df_from_query(sql_ret, use_cols: List[str] = ['id', 'uae_feats', 'bbsd_feats', 'prediction_json']):\n",
    "    current_data = defaultdict(list)\n",
    "    for row in sql_ret:\n",
    "        for col in use_cols:\n",
    "            current_data[col].append(getattr(row, col))\n",
    "    cur_df = pd.DataFrame(current_data).set_index('id')\n",
    "    return cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6176c621-cfce-42d2-878c-b6f5cc578c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pred_json_to_df(pred_json_col: Union[pd.DataFrame, pd.Series]):\n",
    "    return pd.DataFrame(list(pred_json_col.apply(lambda x: json.loads(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5056f23f-8870-46b9-92c1-b3e0b286852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cur_evidently_compat(cur_df: pd.DataFrame, uae_feats_col: str= 'uae_feats',\n",
    "                              bbsd_feats_col: str='bbsd_feats', pred_json_col: str = 'prediction_json'):\n",
    "    uae_feats_arr = np.stack(cur_df[uae_feats_col])\n",
    "    uae_n_feats = uae_feats_arr.shape[1]\n",
    "    uae_feat_cols = [f'uae_feat_{i}' for i in range(uae_n_feats)]\n",
    "    uae_df = pd.DataFrame(uae_feats_arr, columns=uae_feat_cols)\n",
    "    # Create a dup of uae_feat to use for a different purpose\n",
    "    # uae_feat will be used as embeddings for computing drift\n",
    "    # numerical_feat will be used as numerical features for the data quality test\n",
    "    # specifically, TestConflictTarget & TestConflictPrediction\n",
    "    # which are useful to verify. Evidently does not support using the same columns\n",
    "    # twice in column mapping. So, we have to create a duplicate and save them alongside here\n",
    "    num_feat_cols = [f'numerical_feat_{i}' for i in range(uae_n_feats)]\n",
    "    num_df = pd.DataFrame(uae_feats_arr, columns=num_feat_cols)\n",
    "\n",
    "    bbsd_feats_arr = np.stack(cur_df[bbsd_feats_col])\n",
    "    bbsd_n_feats = bbsd_feats_arr.shape[1]\n",
    "    bbsd_feat_cols = [f'bbsd_feat_{i}' for i in range(bbsd_n_feats)]\n",
    "    bbsd_df = pd.DataFrame(bbsd_feats_arr, columns=bbsd_feat_cols)\n",
    "\n",
    "    pred_df = convert_pred_json_to_df(cur_df[pred_json_col])\n",
    "    final_df = pd.concat([num_df, uae_df, bbsd_df, pred_df], axis=1)\n",
    "\n",
    "    # fill columns that exist in ref but not in this cur (label col) with nan\n",
    "    # to make schema of both ref and cur df identical\n",
    "    final_df['label'] = [np.nan] * len(final_df)\n",
    "    \n",
    "    return final_df, num_feat_cols, uae_feat_cols, bbsd_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d91a31-9ff2-49e7-b24b-da7913d24e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ref_evidently_compat(ref_df: pd.DataFrame, classes: List[str], uae_feats_col: str= 'uae_feats',\n",
    "                              bbsd_feats_col: str='bbsd_feats', label_col: str = 'label'):\n",
    "    uae_feats_arr = np.stack(ref_df[uae_feats_col])\n",
    "    uae_n_feats = uae_feats_arr.shape[1]\n",
    "    uae_feat_cols = [f'uae_feat_{i}' for i in range(uae_n_feats)]\n",
    "    uae_df = pd.DataFrame(uae_feats_arr, columns=uae_feat_cols)\n",
    "    # Create a dup of uae_feat to use for a different purpose\n",
    "    num_feat_cols = [f'numerical_feat_{i}' for i in range(uae_n_feats)]\n",
    "    num_df = pd.DataFrame(uae_feats_arr, columns=num_feat_cols)\n",
    "    \n",
    "    bbsd_feats_arr = np.stack(ref_df[bbsd_feats_col])\n",
    "    bbsd_n_feats = bbsd_feats_arr.shape[1]\n",
    "    bbsd_feat_cols = [f'bbsd_feat_{i}' for i in range(bbsd_n_feats)]\n",
    "    bbsd_df = pd.DataFrame(bbsd_feats_arr, columns=bbsd_feat_cols)\n",
    "    \n",
    "    final_df = pd.concat([num_df, uae_df, bbsd_df], axis=1)\n",
    "    \n",
    "\n",
    "    # fill columns that exist in cur but not in this ref (prediction cols) with nan\n",
    "    # to make schema of both ref and cur df identical\n",
    "    for class_name in classes:\n",
    "        final_df[class_name] = [np.nan] * len(final_df)\n",
    "\n",
    "    final_df['label'] = ref_df[label_col].apply(lambda x: np.argmax(x))\n",
    "    \n",
    "    return final_df, num_feat_cols, uae_feat_cols, bbsd_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab90060-830b-40ba-b6f7-d9cb1dc830ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_col_mapping(classes, num_feat_cols, uae_feat_cols, bbsd_feat_cols):\n",
    "    column_mapping = ColumnMapping()\n",
    "\n",
    "    column_mapping.target = 'label'\n",
    "    column_mapping.numerical_features = num_feat_cols\n",
    "    column_mapping.prediction = classes\n",
    "    column_mapping.embeddings = {'uae': uae_feat_cols, 'bbsd': bbsd_feat_cols}\n",
    "    column_mapping.id = None\n",
    "    column_mapping.datetime = None\n",
    "    \n",
    "    return column_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf6f433-1d50-4b96-870e-21c61150d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949a632-bcf1-47fb-be01-4bff51958b63",
   "metadata": {},
   "source": [
    "## Get current data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e717345b-f635-4299-be63-6e1822cdb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '5432')\n",
    "DB_CONNECTION_URL = os.getenv('DB_CONNECTION_URL', f'postgresql://dlservice_user:SuperSecurePwdHere@postgres:{POSTGRES_PORT}/dlservice_pg_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8803e2-fdad-471f-a285-77c7f29ca69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DB_CONNECTION_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "938a5325-0901-4d07-ad77-e3974db1e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = open_db_session(engine)\n",
    "# latest N elements\n",
    "ret = session.query(PredictionsTable).order_by(PredictionsTable.id.desc()).limit(100).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2799ca-2635-48da-9b0f-9112288d7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cur_df = get_cur_df_from_query(ret, use_cols=['id', 'uae_feats', 'bbsd_feats', 'prediction_json'])\n",
    "cur_df, cur_num_feat_cols, cur_uae_feat_cols, cur_bbsd_feat_cols = make_cur_evidently_compat(temp_cur_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605961a5-f537-42c6-8ca9-032f84c63ff4",
   "metadata": {},
   "source": [
    "## Get ref data (from .parquet file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "732326a4-1345-4ccc-91a6-b85ccd64e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = '/home/ariya/central_storage/ref_data/animals10_classifier_50px_trial1_ref_data.parquet'\n",
    "temp_ref_df = pd.read_parquet(ref_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca0fd9b-3bdb-41b2-8592-852e46e8b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df, ref_num_feat_cols, ref_uae_feat_cols, ref_bbsd_feat_cols = make_ref_evidently_compat(temp_ref_df, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6eca223-3772-4580-8a79-1b2ba59ef415",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(ref_df.columns).difference(set(cur_df.columns)) != set():\n",
    "    raise Exception('Columns of ref and cur data are not equal, please reverify.')\n",
    "column_mapping = create_col_mapping(classes, ref_num_feat_cols, ref_uae_feat_cols, ref_bbsd_feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98845b52-3568-46b2-bebd-c694a2db968b",
   "metadata": {},
   "source": [
    "## Build reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b493410-5ab5-4816-b839-bcb683ef7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "224bb3e4-0706-4526-af91-efc3a92c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_NAME = \"production_models_monitor\"\n",
    "ws = Workspace.create(WORKSPACE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98ff3702-85ff-4525-9a98-a3d21e3d0258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project already exists. Use the latest one.\n"
     ]
    }
   ],
   "source": [
    "project_name = 'animals10_monitor'\n",
    "search_results = ws.search_project(project_name)\n",
    "\n",
    "if len(search_results) == 0:\n",
    "    print('Created a new project')\n",
    "    project = ws.create_project(project_name)\n",
    "else:\n",
    "    # select the latest one\n",
    "    print('Project already exists. Use the latest one.')\n",
    "    project = search_results[-1]\n",
    "\n",
    "if first_time:\n",
    "    project = modify_dashboard(project, project_desc='Try Evidently')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85e4d857-adc0-41e7-ab35-30f67c676949",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = create_report()\n",
    "test_suite = create_test_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0520e896-92c5-4513-9c7d-a8c4a2cf8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs took quite long, maybe set bootstrap = False\n",
    "# bug encountered (in 0.4.3), mmd method cannot have the ref data greater than 1000x of cur data (reported)\n",
    "report.run(reference_data=ref_df, current_data=cur_df, column_mapping=column_mapping)\n",
    "test_suite.run(reference_data=ref_df, current_data=cur_df, column_mapping=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d7d962e-cf1d-43f2-a188-3758b0b57445",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.add_report(project.id, report)\n",
    "ws.add_test_suite(project.id, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a030a1-41c5-4ba6-9740-889703ac4645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-viz-dl",
   "language": "python",
   "name": "computer-viz-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
