{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae87315-e4bb-4d91-9c93-0cfa304bae26",
   "metadata": {},
   "source": [
    "## List of features from Evidently we will use\n",
    "Data drift doc: https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_ks_cifar10.html  \n",
    "Data drift ref paper: https://arxiv.org/pdf/1810.11953.pdf\n",
    "- Data Quality (seems not to be applicable)\n",
    "    - Metrics\n",
    "        - ConflictPredictionMetric (for cur)\n",
    "        - ConflictTargetMetric (for ref)\n",
    "        - DatasetCorrelationsMetric\n",
    "    - Tests\n",
    "        - TestConflictPrediction (for cur)\n",
    "        - TestConflictTarget (for ref)\n",
    "        - TestPredictionFeaturesCorrelations\n",
    "- Data Drift\n",
    "    - Metrics\n",
    "        - EmbeddingsDriftMetric (for customization)\n",
    "        - DataDriftPreset\n",
    "    - Tests\n",
    "        - TestEmbeddingsDrift (for customization)\n",
    "        - NoTargetPerformanceTestPreset\n",
    "        - DataDriftTestPreset (subset of NoTargetPerformanceTestPreset, but focus only embeddings-related)\n",
    "        - Custom UAE (?)\n",
    "        - Custom BBSDs (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c59bbe-dd4d-46b9-8241-12a2072557a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.test_preset import NoTargetPerformanceTestPreset, DataDriftTestPreset\n",
    "from evidently.ui.remote import RemoteWorkspace\n",
    "from evidently.ui.workspace import Workspace, WorkspaceBase\n",
    "from evidently.metrics import (ConflictPredictionMetric, DatasetCorrelationsMetric,\n",
    "                               EmbeddingsDriftMetric, ConflictTargetMetric)\n",
    "from evidently.tests import (TestConflictPrediction, TestPredictionFeaturesCorrelations,\n",
    "                             TestEmbeddingsDrift, TestConflictTarget)\n",
    "from evidently.ui.dashboards import (CounterAgg, DashboardPanelCounter, DashboardPanelPlot, \n",
    "                                     PanelValue, PlotType, ReportFilter)\n",
    "from evidently.metrics.data_drift.embedding_drift_methods import model, ratio, distance, mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19827c8-45aa-4fd7-884b-33fd419179e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report():\n",
    "    data_drift_report = Report(\n",
    "        metrics=[\n",
    "            # ConflictTargetMetric(),\n",
    "            # ConflictPredictionMetric(),\n",
    "            \n",
    "            # model with uae\n",
    "            EmbeddingsDriftMetric('uae', drift_method = model(threshold = 0.75)),\n",
    "            # mmd with bbsd\n",
    "            EmbeddingsDriftMetric('bbsd', drift_method = mmd(threshold = 0.015, quantile_probability = 0.95)),\n",
    "            # ks with bbsd\n",
    "            EmbeddingsDriftMetric('bbsd', drift_method = ratio(\n",
    "                                        component_stattest='ks',\n",
    "                                        threshold = 0.05\n",
    "                                    )\n",
    "                                 ),\n",
    "            # DatasetCorrelationsMetric()\n",
    "        ]\n",
    "    )\n",
    "    return data_drift_report\n",
    "\n",
    "\n",
    "def create_test_suite():\n",
    "    data_drift_test_suite = TestSuite(\n",
    "        tests=[\n",
    "            # TestConflictTarget(),\n",
    "            # TestConflictPrediction(),\n",
    "            \n",
    "            # model with uae\n",
    "            TestEmbeddingsDrift('uae', drift_method = model(threshold = 0.75)),\n",
    "            # mmd with bbsd\n",
    "            TestEmbeddingsDrift('bbsd', drift_method = mmd(threshold = 0.015, quantile_probability = 0.95)),\n",
    "            # ks with bbsd\n",
    "            TestEmbeddingsDrift('bbsd', drift_method = ratio(\n",
    "                                        component_stattest='ks',\n",
    "                                        threshold = 0.05\n",
    "                                    )\n",
    "                                 ),\n",
    "            \n",
    "            # TestPredictionFeaturesCorrelations()\n",
    "        ]\n",
    "    )\n",
    "    return data_drift_test_suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cee838f-f2fa-43e5-b641-716a9ab52f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modify_project(project, project_desc: str):\n",
    "    project.description = project_desc\n",
    "    project.dashboard.add_panel(\n",
    "        DashboardPanelCounter(\n",
    "            filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "            agg=CounterAgg.NONE,\n",
    "            title=\"I believe this is the title!\",\n",
    "        )\n",
    "    )\n",
    "    # project.dashboard.add_panel(\n",
    "    #     DashboardPanelCounter(\n",
    "    #         title=\"Model Calls\",\n",
    "    #         filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "    #         value=PanelValue(\n",
    "    #             metric_id=\"DatasetMissingValuesMetric\",\n",
    "    #             field_path=DatasetMissingValuesMetric.fields.current.number_of_rows,\n",
    "    #             legend=\"count\",\n",
    "    #         ),\n",
    "    #         text=\"count\",\n",
    "    #         agg=CounterAgg.SUM,\n",
    "    #         size=1,\n",
    "    #     )\n",
    "    # )\n",
    "    # project.dashboard.add_panel(\n",
    "    #     DashboardPanelCounter(\n",
    "    #         title=\"Share of Drifted Features\",\n",
    "    #         filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "    #         value=PanelValue(\n",
    "    #             metric_id=\"DatasetDriftMetric\",\n",
    "    #             field_path=\"share_of_drifted_columns\",\n",
    "    #             legend=\"share\",\n",
    "    #         ),\n",
    "    #         text=\"share\",\n",
    "    #         agg=CounterAgg.LAST,\n",
    "    #         size=1,\n",
    "    #     )\n",
    "    # )\n",
    "    # project.dashboard.add_panel(\n",
    "    #     DashboardPanelPlot(\n",
    "    #         title=\"Dataset Quality\",\n",
    "    #         filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "    #         values=[\n",
    "    #             PanelValue(metric_id=\"DatasetDriftMetric\", field_path=\"share_of_drifted_columns\", legend=\"Drift Share\"),\n",
    "    #             PanelValue(\n",
    "    #                 metric_id=\"DatasetMissingValuesMetric\",\n",
    "    #                 field_path=DatasetMissingValuesMetric.fields.current.share_of_missing_values,\n",
    "    #                 legend=\"Missing Values Share\",\n",
    "    #             ),\n",
    "    #         ],\n",
    "    #         plot_type=PlotType.LINE,\n",
    "    #     )\n",
    "    # )\n",
    "    # project.dashboard.add_panel(\n",
    "    #     DashboardPanelPlot(\n",
    "    #         title=\"Age: Wasserstein drift distance\",\n",
    "    #         filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "    #         values=[\n",
    "    #             PanelValue(\n",
    "    #                 metric_id=\"ColumnDriftMetric\",\n",
    "    #                 metric_args={\"column_name.name\": \"age\"},\n",
    "    #                 field_path=ColumnDriftMetric.fields.drift_score,\n",
    "    #                 legend=\"Drift Score\",\n",
    "    #             ),\n",
    "    #         ],\n",
    "    #         plot_type=PlotType.BAR,\n",
    "    #         size=1,\n",
    "    #     )\n",
    "    # )\n",
    "    # project.dashboard.add_panel(\n",
    "    #     DashboardPanelPlot(\n",
    "    #         title=\"Education-num: Wasserstein drift distance\",\n",
    "    #         filter=ReportFilter(metadata_values={}, tag_values=[]),\n",
    "    #         values=[\n",
    "    #             PanelValue(\n",
    "    #                 metric_id=\"ColumnDriftMetric\",\n",
    "    #                 metric_args={\"column_name.name\": \"education-num\"},\n",
    "    #                 field_path=ColumnDriftMetric.fields.drift_score,\n",
    "    #                 legend=\"Drift Score\",\n",
    "    #             ),\n",
    "    #         ],\n",
    "    #         plot_type=PlotType.BAR,\n",
    "    #         size=1,\n",
    "    #     )\n",
    "    # )\n",
    "    project.save()\n",
    "    return project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3500e77a-dd35-4ee6-9ae6-d78db8794e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Union, List, Dict\n",
    "from collections import defaultdict\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from db_tables import APILogTable, PredictionsTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5abc84a6-eef7-4c04-b139-31535742442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_db_session(engine: sqlalchemy.engine) -> sqlalchemy.orm.Session:\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e5c63a-edb4-4cbe-ad29-983460af741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cur_df_from_query(sql_ret, use_cols: List[str] = ['id', 'uae_feats', 'bbsd_feats', 'prediction_json']):\n",
    "    current_data = defaultdict(list)\n",
    "    for row in sql_ret:\n",
    "        for col in use_cols:\n",
    "            current_data[col].append(getattr(row, col))\n",
    "    cur_df = pd.DataFrame(current_data).set_index('id')\n",
    "    return cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6176c621-cfce-42d2-878c-b6f5cc578c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pred_json_to_df(pred_json_col: Union[pd.DataFrame, pd.Series]):\n",
    "    return pd.DataFrame(list(pred_json_col.apply(lambda x: json.loads(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5056f23f-8870-46b9-92c1-b3e0b286852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cur_evidently_compat(cur_df: pd.DataFrame, uae_feats_col: str= 'uae_feats',\n",
    "                              bbsd_feats_col: str='bbsd_feats', pred_json_col: str = 'prediction_json'):\n",
    "    uae_feats_arr = np.stack(cur_df[uae_feats_col])\n",
    "    uae_n_feats = uae_feats_arr.shape[1]\n",
    "    uae_feat_cols = [f'uae_feat_{i}' for i in range(uae_n_feats)]\n",
    "    uae_df = pd.DataFrame(uae_feats_arr, columns=uae_feat_cols)\n",
    "\n",
    "    bbsd_feats_arr = np.stack(cur_df[bbsd_feats_col])\n",
    "    bbsd_n_feats = bbsd_feats_arr.shape[1]\n",
    "    bbsd_feat_cols = [f'bbsd_feat_{i}' for i in range(bbsd_n_feats)]\n",
    "    bbsd_df = pd.DataFrame(bbsd_feats_arr, columns=bbsd_feat_cols)\n",
    "\n",
    "    pred_df = convert_pred_json_to_df(cur_df[pred_json_col])\n",
    "    final_df = pd.concat([uae_df, bbsd_df, pred_df], axis=1)\n",
    "\n",
    "    # fill columns that exist in ref but not in this cur (label col) with nan\n",
    "    # to make schema of both ref and cur df identical\n",
    "    final_df['label'] = [np.nan] * len(final_df)\n",
    "    \n",
    "    return final_df, uae_feat_cols, bbsd_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d91a31-9ff2-49e7-b24b-da7913d24e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ref_evidently_compat(ref_df: pd.DataFrame, classes: List[str], uae_feats_col: str= 'uae_feats',\n",
    "                              bbsd_feats_col: str='bbsd_feats', label_col: str = 'label'):\n",
    "    uae_feats_arr = np.stack(ref_df[uae_feats_col])\n",
    "    uae_n_feats = uae_feats_arr.shape[1]\n",
    "    uae_feat_cols = [f'uae_feat_{i}' for i in range(uae_n_feats)]\n",
    "    uae_df = pd.DataFrame(uae_feats_arr, columns=uae_feat_cols)\n",
    "\n",
    "    bbsd_feats_arr = np.stack(ref_df[bbsd_feats_col])\n",
    "    bbsd_n_feats = bbsd_feats_arr.shape[1]\n",
    "    bbsd_feat_cols = [f'bbsd_feat_{i}' for i in range(bbsd_n_feats)]\n",
    "    bbsd_df = pd.DataFrame(bbsd_feats_arr, columns=bbsd_feat_cols)\n",
    "    \n",
    "    final_df = pd.concat([uae_df, bbsd_df], axis=1)\n",
    "    final_df['label'] = ref_df[label_col].apply(lambda x: np.argmax(x))\n",
    "\n",
    "    # fill columns that exist in cur but not in this ref (prediction cols) with nan\n",
    "    # to make schema of both ref and cur df identical\n",
    "    for class_name in classes:\n",
    "        final_df[class_name] = [np.nan] * len(final_df)\n",
    "    \n",
    "    return final_df, uae_feat_cols, bbsd_feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab90060-830b-40ba-b6f7-d9cb1dc830ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_col_mapping(classes, uae_feat_cols, bbsd_feat_cols):\n",
    "    column_mapping = ColumnMapping()\n",
    "\n",
    "    column_mapping.target = 'label'\n",
    "    # column_mapping.numerical_features = uae_feat_cols + bbsd_feat_cols\n",
    "    column_mapping.prediction = classes\n",
    "    column_mapping.embeddings = {'uae': uae_feat_cols, 'bbsd': bbsd_feat_cols}\n",
    "    column_mapping.id = None\n",
    "    column_mapping.datetime = None\n",
    "    \n",
    "    return column_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf6f433-1d50-4b96-870e-21c61150d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0949a632-bcf1-47fb-be01-4bff51958b63",
   "metadata": {},
   "source": [
    "## Get current data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e717345b-f635-4299-be63-6e1822cdb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTGRES_PORT = os.getenv('POSTGRES_PORT', '5432')\n",
    "DB_CONNECTION_URL = os.getenv('DB_CONNECTION_URL', f'postgresql://dlservice_user:SuperSecurePwdHere@postgres:{POSTGRES_PORT}/dlservice_pg_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8803e2-fdad-471f-a285-77c7f29ca69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DB_CONNECTION_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "938a5325-0901-4d07-ad77-e3974db1e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = open_db_session(engine)\n",
    "# latest N elements\n",
    "ret = session.query(PredictionsTable).order_by(PredictionsTable.id.desc()).limit(20).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2799ca-2635-48da-9b0f-9112288d7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cur_df = get_cur_df_from_query(ret, use_cols=['id', 'uae_feats', 'bbsd_feats', 'prediction_json'])\n",
    "cur_df, cur_uae_feat_cols, cur_bbsd_feat_cols = make_cur_evidently_compat(temp_cur_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605961a5-f537-42c6-8ca9-032f84c63ff4",
   "metadata": {},
   "source": [
    "## Get ref data (from .parquet file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "732326a4-1345-4ccc-91a6-b85ccd64e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_path = '/home/ariya/central_storage/ref_data/animals10_classifier_50px_trial1_ref_data.parquet'\n",
    "temp_ref_df = pd.read_parquet(ref_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca0fd9b-3bdb-41b2-8592-852e46e8b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df, ref_uae_feat_cols, ref_bbsd_feat_cols = make_ref_evidently_compat(temp_ref_df, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6eca223-3772-4580-8a79-1b2ba59ef415",
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(ref_df.columns).difference(set(cur_df.columns)) != set():\n",
    "    raise Exception('Columns of ref and cur data are not equal, please reverify.')\n",
    "column_mapping = create_col_mapping(classes, ref_uae_feat_cols, ref_bbsd_feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98845b52-3568-46b2-bebd-c694a2db968b",
   "metadata": {},
   "source": [
    "## Build reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "224bb3e4-0706-4526-af91-efc3a92c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_NAME = \"production_model_monitor\"\n",
    "ws = Workspace.create(WORKSPACE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ff3702-85ff-4525-9a98-a3d21e3d0258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project already exists. Use the latest one.\n"
     ]
    }
   ],
   "source": [
    "project_name = 'animals10_monitor'\n",
    "search_results = ws.search_project(project_name)\n",
    "\n",
    "if len(search_results) == 0:\n",
    "    print('Created a new project')\n",
    "    project = workspace.create_project(project_name)\n",
    "else:\n",
    "    # select the latest one\n",
    "    print('Project already exists. Use the latest one.')\n",
    "    project = search_results[-1]\n",
    "\n",
    "project = modify_project(project, project_desc='Try Evidently')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e4d857-adc0-41e7-ab35-30f67c676949",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = create_report()\n",
    "test_suite = create_test_suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0520e896-92c5-4513-9c7d-a8c4a2cf8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.run(reference_data=ref_df, current_data=cur_df, column_mapping=column_mapping)\n",
    "test_suite.run(reference_data=ref_df, current_data=cur_df, column_mapping=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d7d962e-cf1d-43f2-a188-3758b0b57445",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.add_report(project.id, report)\n",
    "ws.add_test_suite(project.id, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f25723-df16-4f62-b7f2-97a688721387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f5c3a-4838-461c-a0b4-66c93c187946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bb8c3-efe6-4107-894a-480637cdecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer-viz-dl",
   "language": "python",
   "name": "computer-viz-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
